---
title:  "[Lecture 2] Image Classification"

categories:
  - cs231n
tags:
  - [yai, cs231n]
 
date: 2022-01-13
last_modified_at: 2022-01-13
---

<img src="https://user-images.githubusercontent.com/86605720/149441037-743edf49-5456-4ca5-bb8a-0d0355a31c22.png" alt="image" style="zoom:80%;" />

---



# 이번 시간에 배울 내용

* Data-Driven Approach
* Nearest Neightbor classifier
* K-Nearest Neighbors classifier
* Setting Hyperparameters
* Parametric Approach : Linear Classifier

---

# image classification

image classification은 computer vision의 core task 중의 하나로, input image에 따른 label을 결정한다. 사람과 컴퓨터가 image를 인식하는데 있어 semantic gap이 존재하는데 사람은 고양이 사진을 보자마자 직관적으로 고양이라고 판단할 수 있지만, 컴퓨터는 이미지를 숫자로 이루어진 3D array로 인식한다. 밑에 참고자료는 Lecture 3의 강의노트인데, 한 slide의 여러 경우의 image classification의 challenge를 담고 있어서 첨부해봤다. 밑의 자료처럼 같은 고양이가 같은 자세로 같은 구도로 사진을 찍는 것이 아니라, 조명이나 자세 그리고 꼬리만 보여주는 등 image classification은 이러한 변화에도 robust하게 이미지를 분류할 수 있어야 한다.

<img src="https://user-images.githubusercontent.com/86605720/149441915-ab06092c-5e5b-4b81-b5cc-a2dba067496f.png" alt="image" style="zoom:80%;" />

---



# Data-Driven Approach

이전에는 **image classification**에서 이미지를 입력하면 바로 이미지를 분류해내는 단일 함수를 만드는 시도를 했다. 예를 들어 고양이를 분류하는 task에서 물체의 edge와 corner를 찾고 명시적인 rule을 적용해서 고양이인지 판단하는 방식이다. 하지만 이러한 방식은 위에서 언급한 다양한 경우의 challenge를 해결하지 못했고 확장불가능한 방식인 것으로 생각된다.

위의 문제를 해결하기 위해 새로운 방식으로 데이터를 다룰 필요가 있는데, **Data -Driven Approach**란 위와 다르게 train dataset으로 모델을 학습시키고 그 모델을 새로운 image에 적용하는 접근 방식을 의미한다.

<img src="https://user-images.githubusercontent.com/86605720/149444993-8050b78e-0e63-4c5e-8bdf-4a21ec228687.png" alt="image" style="zoom:80%;" />

---



# First classifier : Nearest Neighbor

이 chapter에서 소개하는 data-driven approach의 첫번째 image classifier로 **Nearest Neighbor**가 있다. test data를 기존의 train data와 얼마나 유사한지를 비교해서 가장 시각적으로 유사한 image를 test data의 label로 결정하는 것이다.  얼마나 유사한지 판단하는 기준은 L1 distance 혹은 L2 distance를 사용해서 픽셀간 값을 element-wise하게 차이를 계산하는 것이다. **Distance Metric**에 대한 설명은 아래 그림을 첨부한다.

<img src="https://user-images.githubusercontent.com/86605720/149447058-103ad178-4b62-4baa-9cd7-9c892884f7d7.png" alt="image" style="zoom:80%;" />

**K-Nearest Neighbors**는 Nearest Neighbor와는 다르게 k개의 유사한 image를 뽑아서 가장 많이 나온 class를 test image의 label로 결정하는 것이다. Nearest Neighbor에 비해 장점은 이미지의 label을 정하는 decision boundary를 smooth하게 한다는 점이다.

<img src="https://user-images.githubusercontent.com/86605720/149447129-0762a550-5bf8-4e5c-8069-98de57eaacd9.png" alt="image" style="zoom:80%;" />

---



# Hyperparameters & validation set

K-Nearest Neighbors의 성능을 높이기 위해 어떤 Distance Metric을 사용해야 하고, k는 어떤 값으로 설정해야할까? 이처럼 학습으로 update시키는게 아니라 모델을 설계하는데 선택하는 요소를 **Hyperparameter**라고 한다.  어떤 hyperparameter가 성능이 좋을지는 실험해 보기전에는 알기 힘들고, 모든 경우에 대해 시도해보고 찾는 것이 중요하다.

<img src="https://user-images.githubusercontent.com/86605720/149448981-a3716d46-b83d-4fd4-a28c-5f4944413b9a.png" alt="image" style="zoom:80%;" />



* ### **validation set**을 사용하는 이유

적절한 **Hyperparameter**를 설정하기 위해서 **validation set**을 사용해야 한다. model을 학습시키는 이유가 무엇일까? 본적이 없는, 일반적인 모든 image에 대해서 신뢰할 수 있는 결과를 얻기 위함이다. Idea #1처럼 주어진 dataset에만 잘맞는 hyperparameter를 설정하거나 Idea #2처럼 test-set에 맞는 hyperparameter를 설정하면 새로운 data에서도 좋은 성능을 보일지에 대한 신뢰도가 떨어진다. 따라서 Idea #3처럼 별도의 validation set을 나눠서 학습시킬 때마다 hyperparameter를 update하는 것이 더 바람직하다.



* ### K-Nearest Neighbor 의 단점

1. 보통 classifier는 training에서 시간이 오래걸리는 것은 허용하고, prediction은 빠르게 처리하는 것을 원하는데, Nearest Neighbor의 경우 걸리는 시간이 데이터의 갯수에 따라 선형적으로 증가해서 오래 걸린다.
2. Nearest Neighbor의 전제는 distance가 작을수록 image가 유사하다는 것인데, 다른 image인데도 distance가 같은 경우가 많다. 성능이 좋지 않다는 것.

---



# Linear Classification

* ### **CNN 네트워크의 시작**

Linear Classifier는 뒷장에서  소개될 Neural Network의 기본적인 구성요소이다. linear classifier와 함께 CNN, RNN 등을 함께 조합해서 하나의 model을 구성할 수 있다.



* ### Parametric Approach

이전의 Nearest Neighbor처럼 유사한 image를 찾는 것이 아니라 학습과정에서 parameter를 update하는 방식이다. Linear Classifier란 아래 그림처럼 image와 parameter에 대한 근사함수를 적용해서 image를 분류하는 classifier인데, image의 pixel 값과 각 class의 weight를 곱해서 더하는 과정을 거친다. (행렬곱)

<img src="https://user-images.githubusercontent.com/86605720/149449840-f6252cb2-f861-49ea-b68d-d89e8d534fb0.png" alt="image" style="zoom:80%;" />

* ### **Linear Classifier의 단점**

1. image의 feature를 고려하지 않고 color에 의존적이다. 어떤 class의 weight와 비슷한 색상의 image를 class로 판단하는 경향이 있다.
2. 비선형적인 boundary를 만들기 힘들다. 

<img src="https://user-images.githubusercontent.com/86605720/149450668-194a69f0-b210-480d-acd8-9285c75728d4.png" alt="image" style="zoom:80%;" />
